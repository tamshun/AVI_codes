#!/usr/bin/env python3
"""
æ±ç”¨çš„ãª Staff-Customer ä¼šè©±ç·´ç¿’ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAutoGen + Anthropic/Geminiï¼‰- ã‚·ãƒ³ãƒ—ãƒ«ãƒ­ã‚°ç‰ˆ

å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«:
- customer_persona.md: é¡§å®¢ãƒšãƒ«ã‚½ãƒŠã®å®šç¾©ï¼ˆå¿…é ˆï¼‰- ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®LLMè¨­å®š
- staff_persona.md: åº—å“¡/ã‚¹ã‚¿ãƒƒãƒ•ãƒšãƒ«ã‚½ãƒŠã®å®šç¾©ï¼ˆå¿…é ˆï¼‰
- evaluator_prompt.md: è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå¿…é ˆï¼‰
- .env: ANTHROPIC_API_KEY=your_api_key_here ã¾ãŸã¯ GOOGLE_API_KEY=your_api_key_here
"""

import os
import json
from pathlib import Path
from datetime import datetime
import logging
from dotenv import load_dotenv
import asyncio
import traceback

# AutoGené–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from autogen_core.models import UserMessage, ModelInfo # ModelInfo ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import TextMentionTermination

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

class ConversationTestingSystem:
    def __init__(self):
        self.setup_logging()
        self.setup_config() # APIã‚­ãƒ¼ã®ãƒã‚§ãƒƒã‚¯ã‚’ã“ã“ã§è¡Œã†
        self.load_all_prompts()
        self.loop = asyncio.get_event_loop() # æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’å–å¾—
        if self.loop.is_closed():
            self.loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self.loop)

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®šã®åˆæœŸåŒ–"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_filename = log_dir / f"conversation_{timestamp}.log"

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', # ãƒ¬ãƒ™ãƒ«åè¿½åŠ 
            handlers=[
                logging.FileHandler(self.log_filename, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger("ConversationTest")

        self.conversation_log_file = log_dir / f"chat_{timestamp}.json"
        self.conversation_log = []

    def setup_config(self):
        """APIè¨­å®šã®åˆæœŸåŒ–ï¼ˆAnthropic/Geminiå¯¾å¿œï¼‰"""
        self.api_provider = os.getenv('API_PROVIDER', 'anthropic').lower()
        self.customer_model_client = None
        self.staff_model_client = None

        if self.api_provider == 'gemini':
            self._setup_gemini()
        elif self.api_provider == 'anthropic':
            self._setup_anthropic()
        else:
            raise ValueError(f"Unsupported API_PROVIDER: {self.api_provider}. Choose 'anthropic' or 'gemini'.")

        self.logger.info(f"API Provider: {self.api_provider}")

    def _setup_anthropic(self):
        """Anthropic APIè¨­å®š"""
        try:
            from autogen_ext.models.anthropic import AnthropicChatCompletionClient
        except ImportError:
            self.logger.error("AnthropicChatCompletionClient ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚'autogen-ext[anthropic]' ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            raise ImportError("å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install 'autogen-ext[anthropic]' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

        claude_key = os.getenv('ANTHROPIC_API_KEY')
        if not claude_key:
            raise ValueError("ANTHROPIC_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        self.customer_model_client = AnthropicChatCompletionClient(
            model=os.getenv('ANTHROPIC_CUSTOMER_MODEL', "claude-3-haiku-20240307"),
            api_key=claude_key,
        )
        self.logger.info(f"Customer (Anthropic) model: {self.customer_model_client.model}")

        self.staff_model_client = AnthropicChatCompletionClient(
            model=os.getenv('ANTHROPIC_STAFF_MODEL', "claude-3-5-sonnet-20240620"),
            api_key=claude_key,
        )
        self.logger.info(f"Staff/Evaluator (Anthropic) model: {self.staff_model_client.model}")

    def _setup_gemini(self):
        """Google Gemini APIè¨­å®šï¼ˆOpenAIäº’æ›APIä½¿ç”¨ï¼‰"""
        try:
            from autogen_ext.models.openai import OpenAIChatCompletionClient
            # ModelInfo ã¯ autogen_core.models ã‹ã‚‰æ—¢ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿
        except ImportError:
            self.logger.error("OpenAIChatCompletionClient ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚'autogen-ext[openai]' ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            raise ImportError("å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install 'autogen-ext[openai]' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

        google_key = os.getenv('GOOGLE_API_KEY')
        if not google_key:
            raise ValueError("GOOGLE_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        customer_model_name = os.getenv('GEMINI_CUSTOMER_MODEL', "gemini-1.5-flash-latest")
        staff_model_name = os.getenv('GEMINI_STAFF_MODEL', "gemini-1.5-flash-latest")

        model_info_common = ModelInfo(
            family="gemini",
            vision=True,
            function_calling=True,
            json_output=True,
        )

        gemini_api_base_url = os.getenv('GEMINI_API_BASE_URL', "https://generativelanguage.googleapis.com/v1beta")

        self.customer_model_client = OpenAIChatCompletionClient(
            model=customer_model_name,
            api_key=google_key,
            base_url=gemini_api_base_url,
            model_info=model_info_common,
            api_type="google",
        )
        self.logger.info(f"Customer (Gemini) model: {customer_model_name}, Client Base URL: {gemini_api_base_url}")

        self.staff_model_client = OpenAIChatCompletionClient(
            model=staff_model_name,
            api_key=google_key,
            base_url=gemini_api_base_url,
            model_info=model_info_common,
            api_type="google",
        )
        self.logger.info(f"Staff/Evaluator (Gemini) model: {staff_model_name}, Client Base URL: {gemini_api_base_url}")

    def load_file_content(self, file_path: Path, description: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã‚€æ±ç”¨ãƒ¡ã‚½ãƒƒãƒ‰"""
        if not file_path.exists():
            self.logger.error(f"{description}ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            raise FileNotFoundError(f"{description}ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            if not content:
                self.logger.warning(f"{description}ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {file_path}")
            self.logger.info(f"{description}ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {file_path}")
            return content
        except Exception as e:
            self.logger.error(f"{description}ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            raise Exception(f"{description}ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def load_all_prompts(self):
        """å…¨ã¦ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        self.customer_persona = self.load_file_content(
            Path("customer_persona.md"), "é¡§å®¢ãƒšãƒ«ã‚½ãƒŠ"
        )
        self.staff_persona = self.load_file_content(
            Path("staff_persona.md"), "ã‚¹ã‚¿ãƒƒãƒ•ãƒšãƒ«ã‚½ãƒŠ"
        )
        self.evaluator_prompt = self.load_file_content(
            Path("evaluator_prompt.md"), "è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
        )
        if not (self.customer_persona and self.staff_persona and self.evaluator_prompt):
            raise ValueError("å¿…é ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (customer_persona.md, staff_persona.md, evaluator_prompt.md) ã®ã„ãšã‚Œã‹ãŒç©ºã¾ãŸã¯èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")

    def log_conversation(self, speaker: str, content: str):
        """ä¼šè©±å†…å®¹ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
        timestamp = datetime.now().isoformat()
        log_entry = {
            "timestamp": timestamp,
            "speaker": speaker,
            "content": content
        }
        self.conversation_log.append(log_entry)

        try:
            with open(self.conversation_log_file, 'w', encoding='utf-8') as f:
                json.dump(self.conversation_log, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ä¼šè©±ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

        self.logger.info(f"Chat Logged - [{speaker}]: {content[:100]}{'...' if len(content) > 100 else ''}")

    async def create_agents(self, scenario_description: str = "", max_turns: int = 10):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆï¼ˆéåŒæœŸï¼‰"""

        conversation_guidelines = f"""
        ### ä¼šè©±ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
        - 1å›ã®ç™ºè¨€ã¯ç°¡æ½”ã«ï¼ˆ2-4æ–‡ç¨‹åº¦ï¼‰
        - è‡ªç„¶ãªä¼šè©±ã®æµã‚Œã‚’æ„è­˜
        - åŒã˜å†…å®¹ã‚’ç¹°ã‚Šè¿”ã•ãªã„
        - ã“ã‚Œã¯ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã§ã‚ã‚Šã€ç ”ä¿®ã‚„æŒ¯ã‚Šè¿”ã‚Šã®è©±ã¯ç›´æ¥è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚
        - æœ€å¤§{max_turns // 2}å›ç¨‹åº¦ã®ã‚„ã‚Šå–ã‚Šã§ä¼šè©±ã®ç›®çš„ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ã€‚

        ### ä¼šè©±çµ‚äº†æ¡ä»¶
        - ä¼šè©±ã®ç›®çš„ãŒé”æˆã•ã‚Œã€ã“ã‚Œä»¥ä¸Šè©±ã™ã“ã¨ãŒãªã„ã¨åˆ¤æ–­ã—ãŸå ´åˆã€ã‚ãªãŸã®ç™ºè¨€ã®æœ€å¾Œã«ã€ŒDONEã€ã¨ã„ã†å˜èªã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚
        - ä¾‹: ã€Œã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚ã“ã‚Œã§è§£æ±ºã—ã¾ã—ãŸã€‚DONEã€
        - ã€ŒDONEã€ã®å¾Œã«ã¯ã€ã„ã‹ãªã‚‹è¿½åŠ ã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚
        - è³ªå•ã‚„å¿œç­”ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã€ã¾ãŸã¯ç›¸æ‰‹ã®å¿œç­”ã‚’å¾…ã¤ã¹ãå ´åˆã¯ã€ŒDONEã€ã‚’å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚

        ### ç¾åœ¨ã®ã‚·ãƒŠãƒªã‚ª
        {scenario_description}

        ### é‡è¦ãªæ³¨æ„äº‹é …
        - ã‚ãªãŸã¯æŒ‡å®šã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠã«ãªã‚Šãã£ã¦ãã ã•ã„ã€‚
        - ç›´å‰ã®ç›¸æ‰‹ã®ç™ºè¨€ã§ä¼šè©±ãŒçµ‚äº†æ¡ä»¶ã‚’æº€ãŸã—ã¦ã„ã‚‹å ´åˆã§ã‚‚ã€ã‚ãªãŸè‡ªèº«ã®å¿œç­”ã¨ã—ã¦ã€ŒDONEã€ã¨å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šç›¸æ‰‹ãŒã€Œã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚DONEã€ã¨è¨€ã£ãŸã‚‰ã€ã‚ãªãŸã‚‚ã€Œã“ã¡ã‚‰ã“ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚DONEã€ã®ã‚ˆã†ã«ï¼‰ã€‚ãŸã ã—ã€ä¸è‡ªç„¶ãªå ´åˆã¯ç„¡ç†ã«ã€ŒDONEã€ã‚’ç¹°ã‚Šè¿”ã™å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
        - ã€ŒãŠç–²ã‚Œæ§˜ã§ã—ãŸã€ã®ã‚ˆã†ãªãƒ¡ã‚¿çš„ãªç™ºè¨€ã¯é¿ã‘ã¦ãã ã•ã„ã€‚
        """

        customer_system_message = f"{self.customer_persona}\n{conversation_guidelines}"
        self.customer_agent = AssistantAgent(
            name="Customer",
            description="é¡§å®¢/ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå½¹ã€‚ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®LLMã€‚",
            system_message=customer_system_message,
            model_client=self.customer_model_client,
        )

        staff_system_message = f"{self.staff_persona}\n{conversation_guidelines}"
        self.staff_agent = AssistantAgent(
            name="Staff",
            description="ã‚¹ã‚¿ãƒƒãƒ•/ã‚µãƒ¼ãƒ“ã‚¹æä¾›è€…å½¹ã€‚",
            system_message=staff_system_message,
            model_client=self.staff_model_client,
        )

        self.evaluator_agent = AssistantAgent(
            name="Evaluator",
            description="ä¼šè©±å“è³ªã¨ãƒšãƒ«ã‚½ãƒŠä¸€è²«æ€§ã‚’è©•ä¾¡ã™ã‚‹å°‚é–€å®¶ã€‚",
            system_message=self.evaluator_prompt,
            model_client=self.staff_model_client,
        )
        self.logger.info("All agents created successfully.")

    async def run_conversation_test(self, scenario_description: str = "ä¸€èˆ¬çš„ãªä¼šè©±", initial_message_content: str = "ã“ã‚“ã«ã¡ã¯", max_turns: int = 10):
        """ä¼šè©±ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œï¼ˆéåŒæœŸï¼‰- ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ"""

        print("\n" + "=" * 80)
        print("ğŸ­ ä¼šè©±ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ  é–‹å§‹")
        print("=" * 80)
        print(f"ã‚·ãƒŠãƒªã‚ª: {scenario_description}")
        print(f"æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°: {max_turns}")
        print(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« (è©³ç´°): {self.log_filename}")
        print(f"ä¼šè©±ãƒ­ã‚° (JSON): {self.conversation_log_file}")
        print("-" * 80)

        self.logger.info(f"Test session started: Scenario - '{scenario_description}', Initial Message - '{initial_message_content}', Max Turns - {max_turns}")
        self.log_conversation("System", f"ã‚·ãƒŠãƒªã‚ª: {scenario_description}")

        all_final_messages = []

        try:
            await self.create_agents(scenario_description, max_turns)

            print("\nğŸ¬ ä¼šè©±é–‹å§‹...")
            print("=" * 40)

            agents_for_chat = [self.customer_agent, self.staff_agent]

            group_chat = RoundRobinGroupChat(
                participants=agents_for_chat,
                max_turns=max_turns,
                termination_condition=TextMentionTermination('DONE')
            )

            chat_result = await group_chat.run(
                task=scenario_description
            )

            print("\nğŸ“œ ä¼šè©±å±¥æ­´:")
            print("=" * 40)

            if chat_result and hasattr(chat_result, 'messages') and chat_result.messages:
                conversation_history = chat_result.messages
            else:
                self.logger.warning("No conversation history found in chat_result or group_chat.messages.")

            for i, msg_obj in enumerate(conversation_history):
                speaker = "Unknown"
                content = ""

                if isinstance(msg_obj, dict) and "content" in msg_obj and isinstance(msg_obj["content"], str):
                    content = msg_obj["content"]
                    # 'name' ã¾ãŸã¯ 'source' ãŒã‚ã‚Œã°ãã‚Œã‚’ speaker ã¨ã™ã‚‹
                    if "name" in msg_obj and msg_obj["name"]:
                        speaker = msg_obj["name"]
                    elif "source" in msg_obj and msg_obj["source"]: # è¿½åŠ 
                        speaker = msg_obj["source"]
                    elif "role" in msg_obj and msg_obj["role"]:
                         speaker = msg_obj["role"].capitalize()
                elif hasattr(msg_obj, 'content') and isinstance(msg_obj.content, str):
                    content = msg_obj.content
                    if hasattr(msg_obj, 'name') and msg_obj.name:
                        speaker = msg_obj.name
                    elif hasattr(msg_obj, 'source') and msg_obj.source: # è¿½åŠ 
                        speaker = msg_obj.source
                    elif hasattr(msg_obj, 'role') and msg_obj.role:
                        speaker = msg_obj.role.capitalize()
                else:
                    content = str(msg_obj)
                    self.logger.warning(f"Message object at index {i} has no 'content' or is not a string: {msg_obj}")

                # sender å±æ€§ã‹ã‚‰ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (å¿…è¦ã§ã‚ã‚Œã°)
                if speaker == "Unknown" and hasattr(msg_obj, 'sender') and msg_obj.sender and hasattr(msg_obj.sender, 'name'):
                     speaker = msg_obj.sender.name

                if speaker == "User_CLI_Input":
                    speaker = "Customer"

                all_final_messages.append({"source": speaker, "content": content})
                self.log_conversation(speaker, content)
                print(f"\n[{speaker}]: {content}")
                print("-" * 40)

            conversation_ended_naturally = False
            if all_final_messages and "DONE" in all_final_messages[-1]['content'].strip().upper():
                conversation_ended_naturally = True

            total_turns = len(all_final_messages)

            print("\nğŸ¬ ä¼šè©±çµ‚äº†")
            if conversation_ended_naturally:
                self.logger.info("Conversation ended naturally (DONE detected).")
                print("ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æŒ‡ç¤ºã«ã‚ˆã‚Šè‡ªç„¶ãªçµ‚äº†ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸï¼‰")
            else:
                self.logger.info(f"Conversation ended due to max_turns ({max_turns}) or other reasons.")
                print(f"ï¼ˆæœ€å¤§ã‚¿ãƒ¼ãƒ³æ•° {max_turns} ã«åˆ°é”ã—ãŸã‹ã€ä»–ã®ç†ç”±ã§çµ‚äº†ã—ã¾ã—ãŸï¼‰")
            print("=" * 40)

            print("\nğŸ“Š è©•ä¾¡é–‹å§‹...")
            self.logger.info("Starting evaluation phase.")

            conversation_summary_for_eval = "\n".join([
                f"[{msg_item['source']}]: {msg_item['content']}"
                for msg_item in all_final_messages
            ])

            evaluation_input_text = f"""
            ä»¥ä¸‹ã®ä¼šè©±ãƒ­ã‚°å…¨ä½“ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

            ### è©•ä¾¡å¯¾è±¡ã®ä¼šè©±
            {conversation_summary_for_eval}
            """

            evaluation_response_message_obj = await self.evaluator_agent.run(
                task=evaluation_input_text
            )

            if evaluation_response_message_obj:
                if hasattr(evaluation_response_message_obj, 'messages'):
                    evaluation_content = evaluation_response_message_obj.messages[-1].content
                else:
                    evaluation_content = str(evaluation_response_message_obj)
                    self.logger.warning(f"Unexpected evaluation response format: {type(evaluation_response_message_obj)}")
            else:
                self.logger.error("Evaluation agent did not return a response.")
                evaluation_content = "è©•ä¾¡ã‚¨ãƒ©ãƒ¼: è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

            self.log_conversation("Evaluator", evaluation_content)

            print("\n" + "=" * 80)
            print("ğŸ“ è©•ä¾¡çµæœ")
            print("=" * 80)
            print(evaluation_content)
            print("=" * 80)

            self.logger.info("ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†")
            
            # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¯ãƒ­ãƒ¼ã‚º
            await self.customer_model_client.close()
            await self.staff_model_client.close()

            return {
                "chat_messages": all_final_messages,
                "evaluation": evaluation_content,
                "log_file_json": str(self.conversation_log_file),
                "log_file_system": str(self.log_filename),
                "conversation_ended_naturally": conversation_ended_naturally,
                "total_turns": total_turns
            }

        except Exception as e:
            error_msg = f"ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            self.logger.error(error_msg, exc_info=True)
            print(f"\nâŒ {error_msg}")
            traceback.print_exc()
            return None
        finally:
            self.logger.info("Attempting to close LLM clients.")
            try:
                if self.customer_model_client and hasattr(self.customer_model_client, 'close'):
                    await self.customer_model_client.close()
                    self.logger.info("Customer model client closed.")
            except Exception as ce:
                self.logger.error(f"Error closing customer model client: {ce}", exc_info=True)
            try:
                if self.staff_model_client and hasattr(self.staff_model_client, 'close'):
                    await self.staff_model_client.close()
                    self.logger.info("Staff model client closed.")
            except Exception as se:
                self.logger.error(f"Error closing staff model client: {se}", exc_info=True)

    def get_conversation_stats(self) -> dict:
        """ä¼šè©±çµ±è¨ˆã®å–å¾—"""
        if not self.conversation_log:
            return {}

        customer_msgs = len([msg for msg in self.conversation_log if msg["speaker"].lower() == "customer"])
        staff_msgs = len([msg for msg in self.conversation_log if msg["speaker"].lower() == "staff"])

        stats = {
            "total_logged_entries": len(self.conversation_log),
            "customer_messages": customer_msgs,
            "staff_messages": staff_msgs,
            "actual_conversation_turns": customer_msgs + staff_msgs,
            "duration_seconds": None,
            "duration_formatted": "N/A"
        }

        conversation_entries = [
            msg for msg in self.conversation_log
            if msg["speaker"].lower() in ["customer", "staff", "user_cli_input", "user", "system"] # "System"ã‚‚é–‹å§‹ç‚¹ã¨ã—ã¦è€ƒæ…®
        ]

        if len(conversation_entries) >= 1: # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã ã‘ã§ã‚‚æ™‚é–“ã¯è¨ˆç®—ã§ãã‚‹ï¼ˆã»ã¼0ã ãŒï¼‰
            try:
                # æœ€åˆã®æ„å‘³ã®ã‚ã‚‹ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªï¼ˆSystemã®ã‚·ãƒŠãƒªã‚ªè¨­å®šã‚„æœ€åˆã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ï¼‰
                first_entry_time_str = conversation_entries[0]["timestamp"]
                # æœ€å¾Œã®æ„å‘³ã®ã‚ã‚‹ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒª (è©•ä¾¡çµæœã®ä¸€ã¤å‰ã€ã¤ã¾ã‚Šä¼šè©±ã®æœ€å¾Œ)
                # "Evaluator" ã‚’é™¤ãæœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                last_conv_entries = [m for m in conversation_entries if m["speaker"].lower() != "evaluator"]
                if not last_conv_entries: # ä¼šè©±ãŒå…¨ãç„¡ã‹ã£ãŸå ´åˆ
                    last_entry_time_str = first_entry_time_str
                else:
                    last_entry_time_str = last_conv_entries[-1]["timestamp"]

                start_time = datetime.fromisoformat(first_entry_time_str)
                end_time = datetime.fromisoformat(last_entry_time_str)
                duration_delta = end_time - start_time
                stats["duration_seconds"] = duration_delta.total_seconds()
                stats["duration_formatted"] = str(duration_delta)
            except (ValueError, IndexError) as e:
                self.logger.warning(f"Could not parse timestamps for duration calculation: {e}")

        return stats

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ï¼ˆéåŒæœŸï¼‰"""
    test_system = None
    try:
        print("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        test_system = ConversationTestingSystem()
        print("âœ… åˆæœŸåŒ–å®Œäº† (ãƒ­ã‚°ãƒ»APIè¨­å®š)")
        print("âœ… å…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

        print("\nğŸ“‹ ä¼šè©±ãƒ†ã‚¹ãƒˆã®è¨­å®š")
        print("-" * 40)

        scenario = input("ã‚·ãƒŠãƒªã‚ªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆç©ºç™½ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€Œä¸€èˆ¬çš„ãªã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã€ï¼‰: ").strip()
        if not scenario:
            scenario = "ä¸€èˆ¬çš„ãªã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã®ä¼šè©±"

        initial_msg_content = input("æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆç©ºç™½ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€Œã“ã‚“ã«ã¡ã¯ã€ï¼‰: ").strip()
        if not initial_msg_content:
            initial_msg_content = "ã“ã‚“ã«ã¡ã¯ã€‚"

        max_turns=100

        print(f"\nğŸ­ ãƒ†ã‚¹ãƒˆè¨­å®š:")
        print(f"  ã‚·ãƒŠãƒªã‚ª: {scenario}")
        print(f"  åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {initial_msg_content}")
        print(f"  æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°: {max_turns}")

        result = await test_system.run_conversation_test(
            scenario_description=scenario,
            initial_message_content=initial_msg_content,
            max_turns=max_turns
        )

        if result:
            stats = test_system.get_conversation_stats()
            if stats:
                print(f"\nğŸ“Š ä¼šè©±çµ±è¨ˆ:")
                print(f"  è¨˜éŒ²ã•ã‚ŒãŸç·ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªæ•°: {stats.get('total_logged_entries', 'N/A')}")
                print(f"  é¡§å®¢ç™ºè¨€æ•°: {stats.get('customer_messages', 'N/A')}")
                print(f"  ã‚¹ã‚¿ãƒƒãƒ•ç™ºè¨€æ•°: {stats.get('staff_messages', 'N/A')}")
                print(f"  å®Ÿéš›ã®ä¼šè©±ã‚¿ãƒ¼ãƒ³æ•° (é¡§å®¢+ã‚¹ã‚¿ãƒƒãƒ•): {stats.get('actual_conversation_turns', 'N/A')}")
                if stats.get('duration_formatted') != "N/A":
                    print(f"  ä¼šè©±æ™‚é–“ (æ¦‚ç®—): {stats['duration_formatted']}")

            print(f"\nğŸ’¾ ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {result.get('log_file_system', 'N/A')}")
            print(f"ğŸ’¾ ä¼šè©±JSONãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {result.get('log_file_json', 'N/A')}")
            print("\nğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        else:
            print("\nâŒ ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯çµæœã‚’è¿”ã•ãšã«çµ‚äº†ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    except FileNotFoundError as e:
        print(f"\nâŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print("\nğŸ“ å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«:")
        print("  - customer_persona.md")
        print("  - staff_persona.md")
        print("  - evaluator_prompt.md")
        print("  - .env (APIã‚­ãƒ¼è¨­å®š: ANTHROPIC_API_KEY ã¾ãŸã¯ GOOGLE_API_KEY)")
    except ValueError as e:
        print(f"\nâŒ è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print("\nğŸ”§ å¿…è¦ãªè¨­å®š:")
        print("  1. .env ãƒ•ã‚¡ã‚¤ãƒ«ã« ANTHROPIC_API_KEY (ã¾ãŸã¯ GOOGLE_API_KEY) ã‚’è¨­å®š")
        print("  2. API_PROVIDER ç’°å¢ƒå¤‰æ•°ãŒ 'anthropic' ã¾ãŸã¯ 'gemini' ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª")
        print("  3. å…¨ã¦ã®å¿…é ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (customer_persona.md, staff_persona.md, evaluator_prompt.md) ã«å†…å®¹ã‚’è¨˜è¿°")
    except ImportError as e:
        print(f"\nâŒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¨ãƒ©ãƒ¼: {e}")
        print("å¿…è¦ãªPythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰ã®ä¾‹:")
        print("  pip install python-dotenv autogen-core 'autogen-agentchat>=0.2.20' 'autogen-ext[anthropic]' 'autogen-ext[openai]'")
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã›ã¬ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("è©³ç´°ã¯ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        traceback.print_exc()
    finally:
        print("\nã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šå‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()